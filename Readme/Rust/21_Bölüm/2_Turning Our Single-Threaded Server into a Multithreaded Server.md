## ğŸ§µ Tek Ä°ÅŸ ParÃ§acÄ±klÄ± Sunucuyu Ã‡ok Ä°ÅŸ ParÃ§acÄ±klÄ± Sunucuya DÃ¶nÃ¼ÅŸtÃ¼rmek (turning our single-threaded server into a multithreaded server)

Åu anda sunucu, her isteÄŸi sÄ±rayla iÅŸliyor; yani ilk isteÄŸin iÅŸlenmesi bitmeden ikinci baÄŸlantÄ±yÄ± iÅŸlemiyor. Sunucu giderek daha fazla istek alÄ±rsa, bu **seri yÃ¼rÃ¼tme** (serial execution) giderek daha az verimli olur. Ä°ÅŸlenmesi uzun sÃ¼ren bir istek gelirse, ardÄ±ndan gelen istekler hÄ±zlÄ± iÅŸlenebilir olsalar bile bu uzun isteÄŸin bitmesini bekler. Bunu dÃ¼zeltmemiz gerekecek, ancak Ã¶nce sorunu uygulamada gÃ¶relim.

---

## ğŸŒ Mevcut Sunucu UygulamasÄ±nda YavaÅŸ Bir Ä°stek SimÃ¼lasyonu (simulating a slow request in the current server implementation)

YavaÅŸ iÅŸlenen bir isteÄŸin, mevcut sunucu uygulamamÄ±zdaki diÄŸer istekleri nasÄ±l etkilediÄŸine bakalÄ±m. Liste 21-10, `/sleep` yoluna yapÄ±lan isteÄŸi beÅŸ saniyelik bir gecikmeyle simÃ¼le eder: sunucu, yanÄ±t vermeden Ã¶nce beÅŸ saniye uyur.

**Dosya adÄ±:** src/main.rs

```rust
use std::{
    fs,
    io::{BufReader, prelude::*},
    net::{TcpListener, TcpStream},
    thread,
    time::Duration,
};
// --snip--

fn handle_connection(mut stream: TcpStream) {
    // --snip--

    let (status_line, filename) = match &request_line[..] {
        "GET / HTTP/1.1" => ("HTTP/1.1 200 OK", "hello.html"),
        "GET /sleep HTTP/1.1" => {
            thread::sleep(Duration::from_secs(5));
            ("HTTP/1.1 200 OK", "hello.html")
        }
        _ => ("HTTP/1.1 404 NOT FOUND", "404.html"),
    };

    // --snip--
}
```

Liste 21-10: 5 saniye uyutarak yavaÅŸ bir isteÄŸi simÃ¼le etmek

ÃœÃ§ durumumuz olduÄŸu iÃ§in `if` yerine `match` kullanÄ±yoruz. `match`, eÅŸitlik yÃ¶nteminin yaptÄ±ÄŸÄ± gibi otomatik referans alma/bÄ±rakma (automatic referencing/dereferencing) yapmadÄ±ÄŸÄ±ndan, desen eÅŸleÅŸtirmeyi (pattern matching) dize sabitleriyle yapabilmek iÃ§in `request_line`â€™Ä±n bir dilimini (slice) aÃ§Ä±kÃ§a eÅŸleÅŸtiriyoruz.

* Ä°lk kol, Liste 21-9â€™daki `if` bloÄŸuyla aynÄ±dÄ±r.
* Ä°kinci kol, `/sleep` isteÄŸini yakalar; bu istek alÄ±ndÄ±ÄŸÄ±nda sunucu, baÅŸarÄ±lÄ± HTML sayfasÄ±nÄ± dÃ¶ndÃ¼rmeden Ã¶nce beÅŸ saniye uyur.
* ÃœÃ§Ã¼ncÃ¼ kol, Liste 21-9â€™daki `else` bloÄŸuna denktir.

Bu Ã¶rnek, sunucumuzun ne kadar ilkel olduÄŸunu gÃ¶sterir: gerÃ§ek kÃ¼tÃ¼phaneler, birden fazla isteÄŸi tanÄ±mayÄ± Ã§ok daha az ayrÄ±ntÄ±yla halleder!

Sunucuyu `cargo run` ile baÅŸlatÄ±n. ArdÄ±ndan iki tarayÄ±cÄ± penceresi aÃ§Ä±n: biri `http://127.0.0.1:7878/`, diÄŸeri `http://127.0.0.1:7878/sleep`. `/` URIâ€™sini birkaÃ§ kez girerseniz hÄ±zlÄ± yanÄ±t alÄ±rsÄ±nÄ±z. Ancak `/sleep` girdikten sonra `/`â€™u yÃ¼klemeye Ã§alÄ±ÅŸÄ±rsanÄ±z, `/` yanÄ±tÄ±nÄ±n, uyku isteÄŸi beÅŸ saniyesini tamamen doldurana kadar beklediÄŸini gÃ¶rÃ¼rsÃ¼nÃ¼z.

ArdÄ±ndan gelen isteklerin yavaÅŸ bir isteÄŸin arkasÄ±nda birikmesini Ã¶nlemenin birden Ã§ok tekniÄŸi vardÄ±r (BÃ¶lÃ¼m 17â€™deki gibi **async** kullanmak dÃ¢hil); bizim uygulayacaÄŸÄ±mÄ±z yÃ¶ntem bir **iÅŸ parÃ§acÄ±ÄŸÄ± havuzu** (thread pool) olacaktÄ±r.

## ğŸš€ Ä°ÅŸ ParÃ§acÄ±ÄŸÄ± Havuzuyla AktarÄ±mÄ± ArtÄ±rma (improving throughput with a thread pool)

**Ä°ÅŸ parÃ§acÄ±ÄŸÄ± havuzu (thread pool)**, bir gÃ¶revi ele almak iÃ§in bekleyen ve hazÄ±r durumda tutulan oluÅŸturulmuÅŸ iÅŸ parÃ§acÄ±klarÄ± grubudur. Program yeni bir gÃ¶rev (task) aldÄ±ÄŸÄ±nda, havuzdaki iÅŸ parÃ§acÄ±klarÄ±ndan biri bu gÃ¶reve atanÄ±r ve gÃ¶revi iÅŸler. Havuzdaki kalan iÅŸ parÃ§acÄ±klarÄ±, ilk iÅŸ parÃ§acÄ±ÄŸÄ± gÃ¶revini iÅŸlerken gelen diÄŸer gÃ¶revleri ele almak Ã¼zere hazÄ±r bekler. Ä°lk iÅŸ parÃ§acÄ±ÄŸÄ± gÃ¶revini tamamladÄ±ÄŸÄ±nda, yeni bir gÃ¶revi ele almaya hazÄ±r hÃ¢lde **boÅŸta iÅŸ parÃ§acÄ±klarÄ±** havuzuna geri dÃ¶ner. Bir iÅŸ parÃ§acÄ±ÄŸÄ± havuzu, baÄŸlantÄ±larÄ± eÅŸzamanlÄ± (concurrently) iÅŸlemenize imkÃ¢n tanÄ±yarak sunucunuzun **iÅŸleme hacmini (throughput)** artÄ±rÄ±r.

Havuzdaki iÅŸ parÃ§acÄ±ÄŸÄ± sayÄ±sÄ±nÄ±, bizi **hizmet aksatma saldÄ±rÄ±larÄ±na (DoS attacks)** karÅŸÄ± korumak iÃ§in kÃ¼Ã§Ã¼k bir sayÄ±yla sÄ±nÄ±rlayacaÄŸÄ±z; eÄŸer programÄ±mÄ±z her istek geldiÄŸinde yeni bir iÅŸ parÃ§acÄ±ÄŸÄ± oluÅŸtursaydÄ±, sunucumuza 10 milyon istek yapan biri, tÃ¼m sunucu kaynaklarÄ±mÄ±zÄ± tÃ¼ketip istek iÅŸlemesini durma noktasÄ±na getirerek karmaÅŸaya yol aÃ§abilirdi.

SÄ±nÄ±rsÄ±z iÅŸ parÃ§acÄ±ÄŸÄ± oluÅŸturmak yerine, havuzda bekleyen sabit sayÄ±da iÅŸ parÃ§acÄ±ÄŸÄ±mÄ±z olacak. Gelen istekler, iÅŸlenmek Ã¼zere havuza gÃ¶nderilecek. Havuz, gelen isteklerden oluÅŸan bir **kuyruk (queue)** tutacak. Havuzdaki her iÅŸ parÃ§acÄ±ÄŸÄ±, bu kuyruktan bir isteÄŸi alacak, isteÄŸi iÅŸleyecek ve ardÄ±ndan kuyruktan bir sonraki isteÄŸi talep edecek. Bu tasarÄ±mla, **N** iÅŸ parÃ§acÄ±ÄŸÄ± varsa aynÄ± anda en fazla **N** isteÄŸi iÅŸleyebiliriz. Her iÅŸ parÃ§acÄ±ÄŸÄ± uzun sÃ¼ren bir isteÄŸe yanÄ±t veriyorsa, sonraki istekler kuyrukta birikmeye devam edebilir; ancak o noktaya ulaÅŸmadan Ã¶nce iÅŸleyebildiÄŸimiz uzun sÃ¼reli istek sayÄ±sÄ±nÄ± artÄ±rmÄ±ÅŸ oluruz.

Bu teknik, bir web sunucusunun iÅŸleme hacmini artÄ±rmanÄ±n birÃ§ok yolundan sadece biridir. Ä°nceleyebileceÄŸiniz diÄŸer seÃ§enekler arasÄ±nda **Ã§atalla/birleÅŸtir (fork/join) modeli (fork/join model)**, **tek iÅŸ parÃ§acÄ±klÄ± eÅŸzamansÄ±z G/Ã‡ modeli (single-threaded async I/O model)** ve **Ã§ok iÅŸ parÃ§acÄ±klÄ± eÅŸzamansÄ±z G/Ã‡ modeli (multithreaded async I/O model)** bulunur. Bu konu ilginizi Ã§ekiyorsa, diÄŸer Ã§Ã¶zÃ¼mler hakkÄ±nda daha fazla okuyabilir ve bunlarÄ± uygulamayÄ± deneyebilirsiniz; **Rust** gibi dÃ¼ÅŸÃ¼k seviyeli (low-level) bir dilde, bu seÃ§eneklerin hepsi mÃ¼mkÃ¼ndÃ¼r.

Bir iÅŸ parÃ§acÄ±ÄŸÄ± havuzunu uygulamaya baÅŸlamadan Ã¶nce, havuzu kullanmanÄ±n nasÄ±l gÃ¶rÃ¼neceÄŸinden bahsedelim. Kod tasarlamaya Ã§alÄ±ÅŸÄ±rken, Ã¶nce istemci arayÃ¼zÃ¼nÃ¼ yazmak tasarÄ±mÄ±nÄ±zÄ± yÃ¶nlendirmeye yardÄ±mcÄ± olabilir. Kodu, Ã§aÄŸÄ±rmak istediÄŸiniz ÅŸekilde yapÄ±landÄ±rÄ±lmÄ±ÅŸ olacak biÃ§imde **API (API)**â€™sini yazÄ±n; sonra iÅŸlevselliÄŸi, genel **kamuya aÃ§Ä±k API (public API)**â€™yi sonradan tasarlamak yerine bu yapÄ± iÃ§inde uygulayÄ±n.

BÃ¶lÃ¼m 12â€™deki projede **test gÃ¼dÃ¼mlÃ¼ geliÅŸtirme (test-driven development)** kullandÄ±ÄŸÄ±mÄ±z gibi, burada **derleyici gÃ¼dÃ¼mlÃ¼ geliÅŸtirme (compiler-driven development)** kullanacaÄŸÄ±z. Ä°stediÄŸimiz iÅŸlevleri Ã§aÄŸÄ±ran kodu yazacaÄŸÄ±z ve sonra kodun Ã§alÄ±ÅŸmasÄ± iÃ§in sÄ±rada neyi deÄŸiÅŸtirmemiz gerektiÄŸine karar vermek Ã¼zere derleyicinin hatalarÄ±na bakacaÄŸÄ±z. Bunu yapmadan Ã¶nce, baÅŸlangÄ±Ã§ noktasÄ± olarak kullanmayacaÄŸÄ±mÄ±z tekniÄŸi inceleyeceÄŸiz.

---

## ğŸ§µ Her Ä°stek Ä°Ã§in Bir Ä°ÅŸ ParÃ§acÄ±ÄŸÄ± OluÅŸturma (spawning a thread for each request)

Ã–nce, her baÄŸlantÄ± iÃ§in yeni bir iÅŸ parÃ§acÄ±ÄŸÄ± oluÅŸturduÄŸumuzda kodumuzun nasÄ±l gÃ¶rÃ¼nebileceÄŸini keÅŸfedelim. Daha Ã¶nce belirtildiÄŸi gibi, potansiyel olarak sÄ±nÄ±rsÄ±z sayÄ±da iÅŸ parÃ§acÄ±ÄŸÄ± oluÅŸturma sorunlarÄ± nedeniyle bu bizim nihai planÄ±mÄ±z deÄŸildir; ancak Ã¶nce Ã§alÄ±ÅŸan Ã§ok iÅŸ parÃ§acÄ±klÄ± bir sunucu elde etmek iÃ§in iyi bir baÅŸlangÄ±Ã§ noktasÄ±dÄ±r. SonrasÄ±nda, bir iyileÅŸtirme olarak iÅŸ parÃ§acÄ±ÄŸÄ± havuzunu ekleyeceÄŸiz ve iki Ã§Ã¶zÃ¼mÃ¼ karÅŸÄ±laÅŸtÄ±rmak daha kolay olacaktÄ±r. Liste 21-11, `for` dÃ¶ngÃ¼sÃ¼ iÃ§inde her akÄ±ÅŸÄ± (stream) ele almak Ã¼zere yeni bir iÅŸ parÃ§acÄ±ÄŸÄ± oluÅŸturmak iÃ§in `main`â€™de yapÄ±lacak deÄŸiÅŸiklikleri gÃ¶sterir.

**Dosya adÄ±:** src/main.rs

```rust
fn main() {
    let listener = TcpListener::bind("127.0.0.1:7878").unwrap();

    for stream in listener.incoming() {
        let stream = stream.unwrap();

        thread::spawn(|| {
            handle_connection(stream);
        });
    }
}
```

Liste 21-11: Her akÄ±ÅŸ iÃ§in yeni bir iÅŸ parÃ§acÄ±ÄŸÄ± baÅŸlatmak

BÃ¶lÃ¼m 16â€™da Ã¶ÄŸrendiÄŸiniz gibi, `thread::spawn` yeni bir iÅŸ parÃ§acÄ±ÄŸÄ± oluÅŸturur ve ardÄ±ndan **kapatma (closure)** iÃ§indeki kodu yeni iÅŸ parÃ§acÄ±ÄŸÄ±nda Ã§alÄ±ÅŸtÄ±rÄ±r. Bu kodu Ã§alÄ±ÅŸtÄ±rÄ±r ve tarayÄ±cÄ±nÄ±zda `/sleep` ardÄ±ndan iki farklÄ± sekmede `/` yÃ¼klerseniz, `/` isteklerinin `/sleep`â€™in bitmesini beklemek zorunda olmadÄ±ÄŸÄ±nÄ± gerÃ§ekten gÃ¶rÃ¼rsÃ¼nÃ¼z. Ancak belirttiÄŸimiz gibi, bu yaklaÅŸÄ±m sonunda sistemi bunaltacaktÄ±r Ã§Ã¼nkÃ¼ herhangi bir sÄ±nÄ±r olmaksÄ±zÄ±n yeni iÅŸ parÃ§acÄ±klarÄ± oluÅŸturursunuz.

BÃ¶lÃ¼m 17â€™den hatÄ±rlayabileceÄŸiniz Ã¼zere, bu tam da **eÅŸzamansÄ±z programlama (async) ve bekleme (await)** tekniklerinin parladÄ±ÄŸÄ± durumlardandÄ±r! Ä°ÅŸ parÃ§acÄ±ÄŸÄ± havuzunu inÅŸa ederken bunu aklÄ±nÄ±zda tutun ve `async` kullanÄ±ldÄ±ÄŸÄ±nda nelerin farklÄ± veya aynÄ± gÃ¶rÃ¼neceÄŸini dÃ¼ÅŸÃ¼nÃ¼n.

## âœ… `new` Fonksiyonunda Ä°ÅŸ ParÃ§acÄ±ÄŸÄ± SayÄ±sÄ±nÄ± DoÄŸrulama (validating the number of threads in `new`)

Åu anda `new` ve `execute` fonksiyonlarÄ±nÄ±n parametreleriyle bir ÅŸey yapmÄ±yoruz. Ä°stediÄŸimiz davranÄ±ÅŸla bu fonksiyonlarÄ±n gÃ¶vdelerini (body) uygulayalÄ±m. Ã–ncelikle `new` hakkÄ±nda dÃ¼ÅŸÃ¼nelim. Daha Ã¶nce, havuzdaki iÅŸ parÃ§acÄ±ÄŸÄ± sayÄ±sÄ± iÃ§in iÅŸaretsiz (unsigned) bir tÃ¼r seÃ§miÅŸtik Ã§Ã¼nkÃ¼ negatif sayÄ±da iÅŸ parÃ§acÄ±ÄŸÄ± olan bir havuzun bir anlamÄ± yoktur. Ancak sÄ±fÄ±r iÅŸ parÃ§acÄ±ÄŸÄ± da bir anlam ifade etmez, oysa sÄ±fÄ±r geÃ§erli bir `usize` deÄŸeridir. Bu nedenle, bir `ThreadPool` Ã¶rneÄŸini dÃ¶ndÃ¼rmeden Ã¶nce `size > 0` olduÄŸunu doÄŸrulayan ve sÄ±fÄ±r verilirse programÄ± durduran (`panic`) bir kod ekleyeceÄŸiz. Bunu `assert!` makrosunu kullanarak yapacaÄŸÄ±z (Liste 21-13).

**Dosya adÄ±:** src/lib.rs

```rust
impl ThreadPool {
    /// Create a new ThreadPool.
    ///
    /// The size is the number of threads in the pool.
    ///
    /// # Panics
    ///
    /// The `new` function will panic if the size is zero.
    pub fn new(size: usize) -> ThreadPool {
        assert!(size > 0);

        ThreadPool
    }

    // --snip--
}
```

Liste 21-13: `ThreadPool::new` iÃ§inde sÄ±fÄ±r verilirse panic olacak ÅŸekilde doÄŸrulama

Burada ayrÄ±ca `ThreadPool` iÃ§in **dokÃ¼man yorumlarÄ± (doc comments)** ekledik. Ä°yi dokÃ¼mantasyon uygulamalarÄ±na uyarak, fonksiyonun hangi durumlarda `panic` oluÅŸturabileceÄŸini belirttik (BÃ¶lÃ¼m 14â€™te tartÄ±ÅŸÄ±ldÄ±ÄŸÄ± gibi). `cargo doc --open` komutunu Ã§alÄ±ÅŸtÄ±rÄ±p `ThreadPool` structâ€™Ä±nÄ± tÄ±klayarak `new` fonksiyonu iÃ§in oluÅŸturulan belgeleri gÃ¶rebilirsiniz.

`assert!` eklemek yerine, `new` fonksiyonunu `build` olarak deÄŸiÅŸtirebilir ve bir `Result` dÃ¶ndÃ¼rebilirdik (Liste 12-9â€™daki `Config::build` Ã¶rneÄŸinde olduÄŸu gibi). Ancak bu durumda, iÅŸ parÃ§acÄ±ÄŸÄ± olmadan bir havuz yaratmaya Ã§alÄ±ÅŸmayÄ± **geri dÃ¶ndÃ¼rÃ¼lemez bir hata (unrecoverable error)** olarak deÄŸerlendiriyoruz. Daha iddialÄ± hissediyorsanÄ±z, ÅŸu imzaya sahip bir `build` fonksiyonu yazmayÄ± deneyebilirsiniz:

```rust
pub fn build(size: usize) -> Result<ThreadPool, PoolCreationError> {
```

---

## ğŸ“¦ Ä°ÅŸ ParÃ§acÄ±klarÄ±nÄ± Saklamak iÃ§in Alan OluÅŸturma (creating space to store the threads)

ArtÄ±k havuza saklanacak geÃ§erli sayÄ±da iÅŸ parÃ§acÄ±ÄŸÄ± olduÄŸundan emin olduÄŸumuza gÃ¶re, bu iÅŸ parÃ§acÄ±klarÄ±nÄ± oluÅŸturup `ThreadPool` structâ€™Ä±nda saklayabiliriz. Ama bir iÅŸ parÃ§acÄ±ÄŸÄ±nÄ± nasÄ±l â€œsaklarÄ±zâ€? Bunun iÃ§in `thread::spawn` fonksiyonunun imzasÄ±na tekrar bakalÄ±m:

```rust
pub fn spawn<F, T>(f: F) -> JoinHandle<T>
where
    F: FnOnce() -> T,
    F: Send + 'static,
    T: Send + 'static,
```

`spawn` fonksiyonu bir `JoinHandle<T>` dÃ¶ndÃ¼rÃ¼r; burada `T`, closureâ€™Ä±n dÃ¶ndÃ¼rdÃ¼ÄŸÃ¼ tÃ¼rdÃ¼r. Bizim durumumuzda iÅŸ parÃ§acÄ±ÄŸÄ± havuzuna ilettiÄŸimiz closureâ€™lar baÄŸlantÄ±yÄ± iÅŸleyecek ve bir ÅŸey dÃ¶ndÃ¼rmeyecek, yani `T` birim tÃ¼r (`()`) olacaktÄ±r.

Liste 21-14â€™teki kod derlenecektir ama henÃ¼z iÅŸ parÃ§acÄ±ÄŸÄ± oluÅŸturmaz. `ThreadPool`â€™un tanÄ±mÄ±nÄ±, iÃ§inde `thread::JoinHandle<()>` Ã¶rneklerinden oluÅŸan bir vektÃ¶r (`Vec`) tutacak ÅŸekilde deÄŸiÅŸtirdik, bu vektÃ¶rÃ¼ `size` kapasitesiyle baÅŸlattÄ±k, bir `for` dÃ¶ngÃ¼sÃ¼ hazÄ±rladÄ±k ve bu vektÃ¶re iÅŸ parÃ§acÄ±klarÄ± ekleyeceÄŸimiz yeri bÄ±raktÄ±k. Son olarak, `ThreadPool` Ã¶rneÄŸini bu vektÃ¶rle birlikte dÃ¶ndÃ¼rdÃ¼k.

**Dosya adÄ±:** src/lib.rs

```rust
use std::thread;

pub struct ThreadPool {
    threads: Vec<thread::JoinHandle<()>>,
}

impl ThreadPool {
    // --snip--
    pub fn new(size: usize) -> ThreadPool {
        assert!(size > 0);

        let mut threads = Vec::with_capacity(size);

        for _ in 0..size {
            // create some threads and store them in the vector
        }

        ThreadPool { threads }
    }
    // --snip--
}
```

Liste 21-14: `ThreadPool` iÃ§inde iÅŸ parÃ§acÄ±klarÄ±nÄ± saklamak iÃ§in vektÃ¶r oluÅŸturma

Burada, `ThreadPool` iÃ§indeki Ã¶ÄŸelerin tÃ¼rÃ¼ `thread::JoinHandle<()>` olduÄŸu iÃ§in, `std::thread`â€™i kapsama (scope) aldÄ±k.

GeÃ§erli bir boyut alÄ±ndÄ±ÄŸÄ±nda, `ThreadPool` bu boyutta Ã¶ÄŸe tutabilecek bir vektÃ¶r oluÅŸturur. `with_capacity` fonksiyonu, `Vec::new` ile aynÄ± iÅŸi yapar ama Ã¶nemli bir farkla: belleÄŸi Ã¶nceden ayÄ±rÄ±r. KaÃ§ Ã¶ÄŸe saklayacaÄŸÄ±mÄ±zÄ± bildiÄŸimiz iÃ§in, bu yaklaÅŸÄ±m `Vec::new` kullanmaktan biraz daha verimlidir (Ã§Ã¼nkÃ¼ `Vec::new` Ã¶ÄŸeler eklenirken kendini yeniden boyutlandÄ±rÄ±r).

`cargo check` komutunu Ã§alÄ±ÅŸtÄ±rÄ±rsanÄ±z, kodun baÅŸarÄ±yla derlendiÄŸini gÃ¶rmelisiniz.

---

## ğŸ‘· Worker Struct: ThreadPoolâ€™dan Ä°ÅŸ ParÃ§acÄ±ÄŸÄ±na Kod GÃ¶ndermek (a worker struct responsible for sending code from the ThreadPool to a thread)

Liste 21-14â€™te iÅŸ parÃ§acÄ±klarÄ±nÄ± oluÅŸturduÄŸumuz yere bir yorum bÄ±rakmÄ±ÅŸtÄ±k. Åimdi gerÃ§ekten iÅŸ parÃ§acÄ±klarÄ± oluÅŸturmayÄ± nasÄ±l yapacaÄŸÄ±mÄ±za bakalÄ±m. Standart kÃ¼tÃ¼phane `thread::spawn` ile iÅŸ parÃ§acÄ±klarÄ± oluÅŸturmayÄ± saÄŸlar ve bu fonksiyon, iÅŸ parÃ§acÄ±ÄŸÄ± oluÅŸturulduÄŸu anda Ã§alÄ±ÅŸtÄ±rÄ±lacak bir kod alÄ±r. Ancak bizim durumumuzda, iÅŸ parÃ§acÄ±klarÄ±nÄ± oluÅŸturmak ve onlarÄ±n, sonradan gÃ¶ndereceÄŸimiz kodu beklemesini istiyoruz. Standart kÃ¼tÃ¼phanedeki iÅŸ parÃ§acÄ±ÄŸÄ± uygulamasÄ± bunu yapmanÄ±n bir yolunu iÃ§ermez; bunu kendimiz uygulamalÄ±yÄ±z.

Bu davranÄ±ÅŸÄ±, `ThreadPool` ile iÅŸ parÃ§acÄ±klarÄ± arasÄ±nda yeni bir veri yapÄ±sÄ± tanÄ±tarak uygulayacaÄŸÄ±z. Bu yapÄ±ya **Worker** adÄ±nÄ± vereceÄŸiz; bu, havuzlama (pooling) uygulamalarÄ±nda yaygÄ±n bir terimdir. Worker, Ã§alÄ±ÅŸtÄ±rÄ±lmasÄ± gereken kodu alÄ±r ve kendi iÅŸ parÃ§acÄ±ÄŸÄ±nda Ã§alÄ±ÅŸtÄ±rÄ±r.

Bir restoranÄ±n mutfaÄŸÄ±ndaki Ã§alÄ±ÅŸanlarÄ± dÃ¼ÅŸÃ¼nÃ¼n: iÅŸÃ§iler mÃ¼ÅŸteri sipariÅŸleri gelene kadar beklerler, ardÄ±ndan sipariÅŸleri alÄ±p yerine getirirler.

ArtÄ±k `ThreadPool` iÃ§inde `JoinHandle<()>`â€™lardan oluÅŸan bir vektÃ¶r tutmak yerine, **Worker struct**â€™larÄ± saklayacaÄŸÄ±z. Her Worker, tek bir `JoinHandle<()>` saklayacak. Daha sonra Workerâ€™a, Ã§alÄ±ÅŸtÄ±rÄ±lacak kodu alan ve bunu halihazÄ±rda Ã§alÄ±ÅŸan iÅŸ parÃ§acÄ±ÄŸÄ±na gÃ¶nderen bir yÃ¶ntem (method) uygulayacaÄŸÄ±z. AyrÄ±ca, havuzdaki Worker Ã¶rneklerini ayÄ±rt edebilmek iÃ§in her birine bir `id` vereceÄŸiz.

Yeni `ThreadPool` oluÅŸturulduÄŸunda sÃ¼reÃ§ ÅŸÃ¶yle olacak:

1. `id` ve `JoinHandle<()>` tutan bir `Worker` struct tanÄ±mlayÄ±n.
2. `ThreadPool`â€™u, Worker Ã¶rneklerinden oluÅŸan bir vektÃ¶r tutacak ÅŸekilde deÄŸiÅŸtirin.
3. `Worker::new` fonksiyonunu tanÄ±mlayÄ±n: bir `id` alsÄ±n ve bu `id` ile birlikte boÅŸ bir closure Ã§alÄ±ÅŸtÄ±ran bir iÅŸ parÃ§acÄ±ÄŸÄ± oluÅŸtursun.
4. `ThreadPool::new` iÃ§inde `for` dÃ¶ngÃ¼sÃ¼nÃ¼n sayacÄ±nÄ± `id` olarak kullanÄ±n, yeni bir Worker oluÅŸturun ve vektÃ¶re ekleyin.

HazÄ±r mÄ±sÄ±nÄ±z? Ä°ÅŸte bu deÄŸiÅŸiklikleri uygulayan Liste 21-15:

**Dosya adÄ±:** src/lib.rs

```rust
use std::thread;

pub struct ThreadPool {
    workers: Vec<Worker>,
}

impl ThreadPool {
    // --snip--
    pub fn new(size: usize) -> ThreadPool {
        assert!(size > 0);

        let mut workers = Vec::with_capacity(size);

        for id in 0..size {
            workers.push(Worker::new(id));
        }

        ThreadPool { workers }
    }
    // --snip--
}

struct Worker {
    id: usize,
    thread: thread::JoinHandle<()>,
}

impl Worker {
    fn new(id: usize) -> Worker {
        let thread = thread::spawn(|| {});

        Worker { id, thread }
    }
}
```

Liste 21-15: `ThreadPool` iÃ§inde iÅŸ parÃ§acÄ±klarÄ±nÄ± doÄŸrudan tutmak yerine Worker Ã¶rnekleri saklamak

Burada, `ThreadPool` iÃ§indeki alanÄ±n adÄ±nÄ± `threads`â€™ten `workers`â€™a deÄŸiÅŸtirdik Ã§Ã¼nkÃ¼ artÄ±k `JoinHandle<()>` deÄŸil, Worker Ã¶rnekleri tutuyoruz. `for` dÃ¶ngÃ¼sÃ¼ndeki sayacÄ± `Worker::new`â€™a argÃ¼man olarak veriyoruz ve her yeni Workerâ€™Ä± `workers` adlÄ± vektÃ¶rde saklÄ±yoruz.

DÄ±ÅŸarÄ±daki kod (Ã¶rneÄŸin `src/main.rs` iÃ§indeki sunucumuz) `ThreadPool` iÃ§inde Worker struct kullanÄ±ldÄ±ÄŸÄ±nÄ± bilmek zorunda deÄŸildir; bu nedenle Worker struct ve onun `new` fonksiyonunu **Ã¶zel (private)** yapÄ±yoruz. `Worker::new`, kendisine verdiÄŸimiz `id`â€™yi saklar ve boÅŸ bir closure Ã§alÄ±ÅŸtÄ±rarak oluÅŸturulan bir `JoinHandle<()>` Ã¶rneÄŸini barÄ±ndÄ±rÄ±r.

Not: EÄŸer iÅŸletim sistemi yeterli kaynak olmadÄ±ÄŸÄ± iÃ§in iÅŸ parÃ§acÄ±ÄŸÄ± oluÅŸturamazsa, `thread::spawn` **panic** oluÅŸturur. Bu durumda, bazÄ± iÅŸ parÃ§acÄ±klarÄ± baÅŸarÄ±yla oluÅŸturulsa bile tÃ¼m sunucumuz panic ile Ã§Ã¶ker. Basitlik aÃ§Ä±sÄ±ndan bu davranÄ±ÅŸ kabul edilebilir, ancak Ã¼retim (production) dÃ¼zeyinde bir iÅŸ parÃ§acÄ±ÄŸÄ± havuzu uygulamasÄ±nda `std::thread::Builder` ve onun `Result` dÃ¶ndÃ¼ren `spawn` metodunu kullanmak daha doÄŸru olur.

Bu kod derlenecek ve `ThreadPool::new` fonksiyonuna verdiÄŸimiz sayÄ± kadar Worker Ã¶rneÄŸini saklayacaktÄ±r. Ancak hÃ¢lÃ¢ `execute` fonksiyonuna verilen closureâ€™Ä± iÅŸlemiyoruz. Bir sonraki adÄ±mda bunun nasÄ±l yapÄ±lacaÄŸÄ±nÄ± inceleyeceÄŸiz.

## âš™ï¸ `execute` Metodunun UygulanmasÄ± (implementing the execute method)

Åimdi nihayet `ThreadPool` Ã¼zerinde `execute` metodunu uygulayalÄ±m. AyrÄ±ca `Job` tipini bir `struct` olmaktan Ã§Ä±karÄ±p, `execute`â€™Ä±n aldÄ±ÄŸÄ± closure tÃ¼rÃ¼nÃ¼ tutan bir **trait nesnesi (trait object)** iÃ§in **tip takma adÄ± (type alias)** hÃ¢line getireceÄŸiz. BÃ¶lÃ¼m 20â€™de â€œType Aliases ile TÃ¼r EÅŸanlamlÄ±larÄ± OluÅŸturmakâ€ kÄ±smÄ±nda tartÄ±ÅŸÄ±ldÄ±ÄŸÄ± gibi, tip takma adlarÄ± uzun tÃ¼rleri kÄ±saltarak kullanÄ±mÄ± kolaylaÅŸtÄ±rÄ±r. Liste 21-19â€™a bakÄ±n.

**Dosya adÄ±:** src/lib.rs

```rust
// --snip--

type Job = Box<dyn FnOnce() + Send + 'static>;

impl ThreadPool {
    // --snip--

    pub fn execute<F>(&self, f: F)
    where
        F: FnOnce() + Send + 'static,
    {
        let job = Box::new(f);

        self.sender.send(job).unwrap();
    }
}

// --snip--
```

Liste 21-19: Her closureâ€™Ä± tutan bir Box iÃ§in `Job` tip takma adÄ± oluÅŸturmak ve iÅŸi kanaldan (channel) gÃ¶ndermek

Burada, `execute` ile aldÄ±ÄŸÄ±mÄ±z closureâ€™dan yeni bir `Job` Ã¶rneÄŸi oluÅŸturuyoruz ve bu iÅŸi kanalÄ±n gÃ¶nderici (sender) ucundan gÃ¶nderiyoruz. `send` Ã§aÄŸrÄ±sÄ±na `unwrap` ekliyoruz; bu, gÃ¶nderme baÅŸarÄ±sÄ±z olursa panic olacaktÄ±r. Bu baÅŸarÄ±sÄ±zlÄ±k Ã¶rneÄŸin tÃ¼m iÅŸ parÃ§acÄ±klarÄ±nÄ± durdurduÄŸumuzda (alÄ±cÄ± taraf yeni mesaj almÄ±yorsa) olabilir. Åu anda iÅŸ parÃ§acÄ±klarÄ±nÄ± durduramÄ±yoruz; havuz var oldukÃ§a Ã§alÄ±ÅŸmaya devam ediyorlar. `unwrap` kullanmamÄ±zÄ±n nedeni, baÅŸarÄ±sÄ±zlÄ±k durumunun gerÃ§ekleÅŸmeyeceÄŸini biliyor olmamÄ±z ama derleyicinin bunu bilmemesidir.

---

## ğŸ‘· Worker Ä°Ã§inde Ä°ÅŸleri AlÄ±p Ã‡alÄ±ÅŸtÄ±rma (receiving and executing jobs in the worker)

Ama iÅŸimiz tam bitmedi! Worker iÃ§inde `thread::spawn`â€™a verdiÄŸimiz closure hÃ¢lÃ¢ yalnÄ±zca kanalÄ±n alÄ±cÄ± (receiver) ucuna referans veriyor. Bunun yerine closure, sonsuza dek dÃ¶ngÃ¼ye girip kanaldan iÅŸ istemeli ve iÅŸ geldiÄŸinde onu Ã§alÄ±ÅŸtÄ±rmalÄ±. `Worker::new` iÃ§inde bu deÄŸiÅŸikliÄŸi yapalÄ±m (Liste 21-20).

**Dosya adÄ±:** src/lib.rs

```rust
// --snip--

impl Worker {
    fn new(id: usize, receiver: Arc<Mutex<mpsc::Receiver<Job>>>) -> Worker {
        let thread = thread::spawn(move || {
            loop {
                let job = receiver.lock().unwrap().recv().unwrap();

                println!("Worker {id} got a job; executing.");

                job();
            }
        });

        Worker { id, thread }
    }
}
```

Liste 21-20: Worker Ã¶rneÄŸinin iÅŸ parÃ§acÄ±ÄŸÄ±nda iÅŸleri almak ve yÃ¼rÃ¼tmek

Burada Ã¶nce `receiver.lock()` Ã§aÄŸÄ±rarak mutex kilidini (lock) alÄ±yoruz, sonra `unwrap` ile olasÄ± hatalarda panic oluÅŸturuyoruz. Kilit almak baÅŸarÄ±sÄ±z olabilir; bu, baÅŸka bir iÅŸ parÃ§acÄ±ÄŸÄ± kilidi bÄ±rakmadan panic ettiÄŸinde (mutexâ€™in zehirli olduÄŸu durumda, poisoned) gerÃ§ekleÅŸebilir. Bu durumda panic etmek doÄŸru davranÄ±ÅŸtÄ±r. Dilerseniz `unwrap` yerine `expect` kullanÄ±p anlamlÄ± bir hata mesajÄ± yazabilirsiniz.

Kilit alÄ±ndÄ±ÄŸÄ±nda `recv` Ã§aÄŸÄ±rarak kanaldan bir `Job` alÄ±yoruz. Son bir `unwrap`, burada da olasÄ± hatalarÄ± geÃ§er (Ã¶rneÄŸin gÃ¶nderici taraf kapatÄ±ldÄ±ÄŸÄ±nda).

`recv` Ã§aÄŸrÄ±sÄ± bloklanÄ±r; yani henÃ¼z iÅŸ yoksa, mevcut iÅŸ parÃ§acÄ±ÄŸÄ± yeni bir iÅŸ gelene kadar bekler. `Mutex<T>`, aynÄ± anda yalnÄ±zca bir Worker iÅŸ parÃ§acÄ±ÄŸÄ±nÄ±n iÅŸ talep etmesini saÄŸlar.

ArtÄ±k iÅŸ parÃ§acÄ±ÄŸÄ± havuzumuz Ã§alÄ±ÅŸÄ±r durumda! `cargo run` ile Ã§alÄ±ÅŸtÄ±rÄ±n ve bazÄ± istekler yapÄ±n:

```
$ cargo run
   Compiling hello v0.1.0 (file:///projects/hello)
warning: field `workers` is never read
 --> src/lib.rs:7:5
  |
6 | pub struct ThreadPool {
  |            ---------- field in this struct
7 |     workers: Vec<Worker>,
  |     ^^^^^^^
  |
  = note: `#[warn(dead_code)]` on by default

warning: fields `id` and `thread` are never read
  --> src/lib.rs:48:5
   |
47 | struct Worker {
   |        ------ fields in this struct
48 |     id: usize,
   |     ^^
49 |     thread: thread::JoinHandle<()> ,
   |     ^^^^^^
...
Worker 0 got a job; executing.
Worker 2 got a job; executing.
Worker 1 got a job; executing.
Worker 3 got a job; executing.
...
```

BaÅŸarÄ±! ArtÄ±k baÄŸlantÄ±larÄ± eÅŸzamanlÄ± olarak Ã§alÄ±ÅŸtÄ±ran bir iÅŸ parÃ§acÄ±ÄŸÄ± havuzumuz var. DÃ¶rt iÅŸ parÃ§acÄ±ÄŸÄ±ndan fazlasÄ± hiÃ§bir zaman oluÅŸturulmaz, bu yÃ¼zden sunucu Ã§ok sayÄ±da istek alsa bile sistemimiz aÅŸÄ±rÄ± yÃ¼klenmez. `/sleep` isteÄŸi yaptÄ±ÄŸÄ±nÄ±zda, diÄŸer istekler baÅŸka bir iÅŸ parÃ§acÄ±ÄŸÄ± tarafÄ±ndan yÃ¼rÃ¼tÃ¼lerek sunucu hizmet vermeye devam eder.

Not: `/sleep` adresini aynÄ± anda birden fazla tarayÄ±cÄ± penceresinde aÃ§arsanÄ±z, sayfalar beÅŸer saniye aralÄ±klarla yÃ¼klenebilir. BazÄ± tarayÄ±cÄ±lar, Ã¶nbellekleme nedeniyle aynÄ± isteÄŸin birden fazla Ã¶rneÄŸini sÄ±rasÄ±yla Ã§alÄ±ÅŸtÄ±rÄ±r. Bu sÄ±nÄ±rlama bizim sunucumuzdan deÄŸil, tarayÄ±cÄ±dan kaynaklanÄ±r.

---

## ğŸ”„ `while let` ile Alternatif Worker UygulamasÄ± (alternative implementation with `while let`)

BÃ¶lÃ¼m 17 ve 18â€™deki `while let` dÃ¶ngÃ¼sÃ¼nÃ¼ Ã¶ÄŸrendikten sonra, neden Worker kodunu Liste 21-21â€™deki gibi yazmadÄ±ÄŸÄ±mÄ±zÄ± merak edebilirsiniz.

**Dosya adÄ±:** src/lib.rs
*Bu kod istenen davranÄ±ÅŸÄ± saÄŸlamaz.*

```rust
// --snip--

impl Worker {
    fn new(id: usize, receiver: Arc<Mutex<mpsc::Receiver<Job>>>) -> Worker {
        let thread = thread::spawn(move || {
            while let Ok(job) = receiver.lock().unwrap().recv() {
                println!("Worker {id} got a job; executing.");

                job();
            }
        });

        Worker { id, thread }
    }
}
```

Liste 21-21: Worker::new iÃ§in `while let` kullanan alternatif uygulama

Bu kod derlenir ve Ã§alÄ±ÅŸÄ±r, ancak istenen iÅŸ parÃ§acÄ±ÄŸÄ± davranÄ±ÅŸÄ±nÄ± vermez: yavaÅŸ bir istek, diÄŸer isteklerin de beklemesine neden olur. Sebep biraz incedir: `Mutex` structâ€™Ä±nÄ±n herkese aÃ§Ä±k bir `unlock` metodu yoktur Ã§Ã¼nkÃ¼ kilidin sahipliÄŸi, `lock` metodunun dÃ¶ndÃ¼rdÃ¼ÄŸÃ¼ `LockResult<MutexGuard<T>>` iÃ§indeki `MutexGuard<T>`â€™nin Ã¶mrÃ¼ne baÄŸlÄ±dÄ±r. BÃ¶ylece derleme zamanÄ± (compile time) denetleyicisi (borrow checker), bir kaynaÄŸa yalnÄ±zca kilidi tuttuÄŸumuz sÃ¼rece eriÅŸilebileceÄŸini zorunlu kÄ±lar.

Ancak bu uygulama, `MutexGuard<T>`â€™nin Ã¶mrÃ¼ne dikkat etmezsek kilidin istenenden daha uzun sÃ¼re tutulmasÄ±na yol aÃ§abilir.

Liste 21-20â€™de kullandÄ±ÄŸÄ±mÄ±z `let job = receiver.lock().unwrap().recv().unwrap();` ifadesi iÅŸe yarar Ã§Ã¼nkÃ¼ `let` iÃ§inde saÄŸ taraftaki ifadedeki geÃ§ici deÄŸerler, `let` ifadesi bittiÄŸinde hemen dÃ¼ÅŸÃ¼rÃ¼lÃ¼r (drop edilir). Oysa `while let` (ve `if let`, `match`) geÃ§ici deÄŸerleri ilgili blok bitene kadar dÃ¼ÅŸÃ¼rmez. Liste 21-21â€™de, kilit `job()` Ã§aÄŸrÄ±sÄ± boyunca tutulur, bu da diÄŸer Worker Ã¶rneklerinin iÅŸ almasÄ±nÄ± engeller.
